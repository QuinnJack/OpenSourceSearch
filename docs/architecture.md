Notes:



Dataset of 138 AI-generated images, 51 real photos. Outlines factors that affect identifiability of AI images
(Anatomical Implausibility's, Stylistic Artifacts, Functional Implausibility's, Violations of Physics, Sociocultural Implausibility's)
https://arxiv.org/pdf/2406.08651


Kaggle's 2020 Deepfake Detection Challenge.
Dataset: https://www.kaggle.com/datasets/sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset
Nearly all top solutions used a "frame-by-frame classification approach."
https://www.kaggle.com/competitions/deepfake-detection-challenge/writeups/selim-seferbekov-1st-place-solution
The winner provided methodology, examples, code, etc. From 2020 and focusing on "deepfakes" rather than AI-generated. 
https://github.com/selimsef/dfdc_deepfake_challenge

Open-source AI-generated video dataset
htps://arxiv.org/abs/2402.02085v7
(Based on the principle of video frame consistency, we introduce a simple yet effective detection model (DeCoF) that eliminates the impact of spatial artifacts during generalizing feature learning.)



We train three classifiers using 3D convolutional networks, each targeting distinct aspects: vision foundation model features for appearance, optical flow for motion, and monocular depth for geometry. Each classifier exhibits strong performance in fake video detection, both qualitatively and quantitatively. This indicates that AI-generated videos are still easily detectable, and a significant gap between real and fake videos persists.

Our model is capable of detecting videos generated by Sora with high accuracy, even without exposure to any Sora videos during training. This suggests that the gap between real and fake videos can be generalized across various video generative models. 
https://arxiv.org/pdf/2406.19568
https://justin-crchang.github.io/3DCNNDetection.github.io/

Google Cloud Vision API 
to:

    Check if images appear elsewhere online
    Find original sources and contexts
    Identify visually similar images
    Provide best-guess descriptions


2025 1M-Deepfakes Detection Challenge
ACM Multimedia 2025 Oct 29
The new 2025 challenge builds on the successful 2024 challenge to focus on the deepfake detection and localization. This year the challenge is based on new AV-Deepfake1M++ containing over 2 million samples!
https://deepfakes1m.github.io/2025

ACM Multimedia 2024 Grand Challenge Report for Artificial Intelligence Generated Image Detection
https://dl.acm.org/doi/pdf/10.1145/3664647.3689001


1. Color Variance Analysis

This algorithm evaluates pixel colors across frames. Natural videos often exhibit random and diverse color variations, whereas AI-generated videos may appear overly uniform.
2. Edge Complexity Detection

Edge complexity measures the sharpness and transitions of edges in video frames. AI-generated videos often have exaggerated or overly smooth edges compared to natural footage.
3. Texture Uniformity Evaluation

Real-world textures are inherently imperfect. The detector identifies regions with uniform textures, a tell-tale sign of AI generation.


https://thehive.ai/pricing


https://cdn.openai.com/pdf/50d5973c-c4ff-4c2d-986f-c72b5d0ff069/sora_2_system_card.pdf



provenance

https://www.getrealsecurity.com/platform#inspect


https://sightengine.com/detect-ai-generated-images


https://sightengine.com/docs/



Google Custom Search API integration

✗
XiaohuLu RANSAC Detection

Uses RANSAC (Random Sample Consensus) to find vanishing points by detecting parallel lines that converge. Especially good at finding the 3 main directions in "Manhattan world" scenes (buildings with perpendicular walls).

Purpose: Detects architectural geometry violations

Issue: XiaohuLu not installed. Run: cd detectai/external_libs && git clone https://github.com/rayryeng/XiaohuLuVPDetection
✗
GlobustVP Convex Optimization

Advanced algorithm from CVPR 2025 that uses mathematical optimization to find vanishing points. Can handle up to 70% outliers (wrong lines) and still find correct results.

Purpose: Robust detection even with noisy/complex scenes

Issue: GlobustVP not installed. Requires: pip install cvxpy
✓
RANSAC VP Detector

Custom RANSAC implementation that groups lines by orientation and finds where they intersect. Faster than other methods but less sophisticated.

Purpose: Quick initial detection of obvious VP violations

Result: Found 3 vanishing points

Found 3 vanishing points
✓
Heuristic Line Grouping

Basic fallback method that groups similar lines and checks if they converge properly. Always available even when other algorithms fail.

Purpose: Backup detection when advanced algorithms fail

Result: Found 5 VPs with good line support

Found 5 vanishing points







https://sightengine.com/detect-ai-generated-images


geolocation
https://www.bellingcat.com/resources/2025/08/14/llms-vs-geolocation-gpt-5-performs-worse-than-other-ai-models/


https://www.untitledui.com/react/components/file-uploaders


- Upload a image or video, and tools tha




Tabs:

Validity / Provenance

- AI detection (manipulation, “Real but Edited,” confidence)
- Metadata/EXIF (missing/stripped, GPS)
- AI-synthesis, SynthID, notes, origin unknown etc
- Fact-check search (Fact Check Explorer)

Circulation
- Found-on websites (count, earliest appearance)
- Reverse image search (TinEye/Yandex/Bing)

- Fact-check presence
- Example links and timestamps (X/Twitter, news, blogs)
- Similar-images (variants/templates)

Context / Geolocation
- Location analysis (Mount Lee, coords)
- Visual cues (Hollywood Sign, palms, hills)
- Maps/Satellite/Street View
- Tools like CIFCC integrated, geomatics webmaps 


Forensics
- ELA/clone detection (FotoForensics, 29a.ch), MeVer
- Manual zoom/edge/lighting/compositing checks










Core Upload UX

Implement real upload flow (progress, cancel, retry)
Enforce type/size validation for images/videos/docs
Support drag/drop, paste, and multi-file selection
Generate previews and cleanup via URL.revokeObjectURL
Show clear error/empty/disabled states and toasts
Accessibility: focus order, roles, labels, keyboard
Analysis Data Model

Finalize analysis schema for Validity, Circulation, Context, Forensics
Normalize status/severity, timestamps, confidences
Add per-engine result structure + provenance metadata
Add feature flags to enable/disable engines
Define error/timeout semantics per analyzer
Analysis Orchestration (Frontend)

Add orchestrator to fan-out requests per analyzer and merge results
Track loading and partial results per tab/card
Add retries, timeouts, and cancellation per engine
Cache by content hash; hydrate from cache when possible
Pluggable analyzer registry with simple interface
Metadata & EXIF

Integrate EXIF parser (browser-first; fallback to server)
Detect “stripped” EXIF and GPS presence
Map GPS when present; show device/camera info
Present entries in sortable, copyable table
Privacy notice and explicit metadata handling toggle
Validity: AI-Edited Signal

Wire up at least one AI-edit detection provider (mock -> provider)
Aggregate multiple providers to average/weight confidence
Surface confidence with progress/badge states
Handle provider errors gracefully and degrade UI
Base UI & Navigation

Introduce app routing (upload → analyze with deep links)
Persist recent analyses (localStorage/IndexedDB)
Back/forward navigation and shareable result state
Theming polish, responsive layout, skeleton states
Testing & Quality

Unit tests for orchestrator and utilities
Component tests for tabs/cards/upload states
E2E happy path (upload → full analysis render)
ESLint/TypeScript strict and Prettier formatting
CI/CD & DevOps (Minimum)

GitHub Actions: lint/test/build on PRs
Basic Dockerfile and environment variable handling
Preview deploy (e.g., Netlify/Vercel) with protected secrets
Issue templates and PR checklist
Expansion Epics

Circulation (Reverse Image Search)

Adapters for engines (e.g., Google/Bing/Yandex/TinEye; pick feasible set)
Parse results, deduplicate, cluster by domain and visual similarity
Track earliest known appearance and canonical URLs
UI: timeline + paginated result list with thumbnails
Caching and quota/backoff strategies
Context & Geolocation

OCR (e.g., Tesseract) + NER to extract places/orgs/dates
Landmark/logo detection (vision model or API)
Map integration (MapLibre/Leaflet) with evidence markers
User notes/annotations with export/import
Confidence summaries and caveat messaging
Forensics

ELA heatmap generation in a Web Worker
Noise/quantization analysis and clone/splice heuristics
ROI selection and side-by-side comparisons
Overlay controls (opacity, thresholds)
Download/share annotated findings
Backend API (if needed)

File ingestion and temporary storage (S3/MinIO/local)
EXIF parsing fallback (exiftool/exifr server-side)
Proxy/aggregate AI detection and search providers
Rate limiting, auth (API key/session), CORS, logging
Task queue for long-running operations and webhooks
Privacy & Security

Explicit consent for sending media to third-parties
Local-only mode with clear capability limitations
TTL cleanup policy and signed URLs
CSP headers, dependency audits, secret management
Redaction/blur tooling for sensitive regions
Performance & Accessibility

Code-splitting, route-based lazy loading, bundle budget
Web Workers for heavy compute (OCR/ELA)
Virtualize large lists, memoize selectors
A11y audit (ARIA roles, labels, contrast, keyboard traps)
Lighthouse/Perf CI checks
Observability & Product Analytics

Privacy-preserving telemetry (self-hosted or opt-in)
Error reporting and structured logs
Feature flags and experiment toggles
Basic usage dashboards (no content, only events/latency)
Docs & Enablement

Architecture and data flow diagrams
Local dev guide, API docs, environment setup






https://www.reddit.com/r/googlecloud/comments/126efns/is_the_google_images_api_still_available/



# OpenSourceSearch Architecture & Delivery Plan

## Goals
- Deliver a privacy-preserving verification experience that keeps user-supplied API keys on-device for as long as possible.
- Support rapid iteration on new analysis capabilities without destabilising the core upload and review workflow.
- Maintain a modular codebase that scales with additional providers, analyses, and collaboration tooling.

## High-Level System Overview
- **Client Application (React + Vite)**: Renders the workspace, orchestrates uploads, manages state, and coordinates background jobs.
- **Integration Layer (client-side SDKs)**: Adapter wrappers around third-party APIs (OpenAI, Vision APIs, search providers) instantiated with user-provided keys.
- **Local Persistence**: IndexedDB (via `idb` or similar) for large artefacts (files, analysis results), `localStorage`/`sessionStorage` for small preferences, in-memory caches for volatile state.
- **Web Workers**: Offload heavy computation (hashing, EXIF extraction, media preprocessing) to keep the UI responsive.
- **Optional Relay (future)**: Minimal backend only when required for workflow features that cannot stay client-only (shared workspaces, audit trails).

### Layered Architecture
1. **App Shell**: Entry point, routing, React providers (theme, query caching, feature flags).
2. **Feature Modules**: Vertical slices (media verification, circulation search, key management) exposing pages, widgets, and business logic.
3. **Shared Libraries**: Cross-cutting utilities (design system, storage, analytics, hooks, types).
4. **Service Adapters**: Thin clients that abstract provider-specific requests and response normalisation; accept API keys at call time or from a client-side vault.

### Core Client Data Flow
1. **User uploads media** → validated locally and stored in memory / IndexedDB.
2. **User enters API keys** → stored via secure client-side vault (AES via Web Crypto) and loaded into the integration layer on demand.
3. **Analysis pipeline runs** → orchestrator dispatches to enabled providers through adapters; results streamed back and cached.
4. **UI updates** → React Query (or equivalent) manages async status, optimistic updates, and background refresh.

### Key & Secrets Handling
- Never persist keys in plaintext; derive an encryption key from a user-provided passphrase when possible.
- Encapsulate key access through a dedicated `KeyStore` service that exposes `getClient(providerId)` for feature modules.
- Maintain an in-memory mirror that is cleared on tab close or inactivity timeout.

### API Integration Strategy
- Define provider contracts in `src/services/providers/types.ts`.
- Implement adapters in `src/services/providers/{provider}/client.ts`, each returning typed responses.
- Introduce a pipeline controller (`src/features/media-verification/services/pipeline.ts`) responsible for sequencing provider calls, fallbacks, and merging outputs.

### State Management & Communication
- Use React Query (or TanStack Query) for async data fetching and caching; fallback to React context for global ephemeral state (theme, active workspace).
- Share feature state through colocated hooks inside each module.
- Standardise events (e.g., analysis completed, upload failed) via a lightweight event emitter to decouple UI elements.

### Performance & Resilience
- Implement lazy loading for feature bundles.
- Use Web Workers for CPU intensive tasks (perceptual hashing, metadata parsing).
- Provide retry/backoff utilities and graceful degradation when providers are unavailable.

### Testing & Quality
- Unit tests per feature module; contract tests for provider adapters using recorded fixtures.
- Smoke E2Es scripting the client app against mocked adapters to guarantee offline determinism.
- Snapshot visual regression coverage for critical UI states (upload, analysis summary).

## Delivery Roadmap

### Epic 1 — API Key Management, Security, Frontend Skeleton
- Build key vault service with encryption helpers and inactivity timers.
- Create onboarding flow for entering, validating, and testing provider keys.
- Surface provider status indicators in the UI shell.
- Document security posture, handling guidelines, and fallback behaviours.

### Epic 1 — API Key Management, Security, Frontend Skeleton
- Build key vault service with encryption helpers and inactivity timers.
- Create onboarding flow for entering, validating, and testing provider keys.
- Surface provider status indicators in the UI shell.
- Document security posture, handling guidelines, and fallback behaviours.

### Epic 2 — Media Upload & Workspace Experience
- Finalise drag-and-drop, file validation, and compression heuristics.
- Persist uploads to IndexedDB and hydrate state on reload.
- Introduce a workspace timeline showing upload history and status.
- Add error recovery flows (re-try upload, replace file).

### Epic 3 — Analysis Pipeline Foundation
- Create provider adapter interfaces and implement initial provider clients.
- Build analysis orchestrator with progress tracking and cancellation support.
- Normalise provider responses into shared domain models.
- Render analysis results with loading skeletons and empty states.

### Epic 4 — Insights & Collaboration
- Implement circulation/context panels with saved searches and external linkouts.
- Add annotation/commenting primitives on media artefacts.
- Support export (PDF/report) and shareable snapshots once backend is introduced.
- Integrate activity log for provenance and auditability.

### Epic 5 — Observability & Tooling
- Add telemetry hooks (performance timers, error boundaries, logging).
- Configure storybook (or similar) for design system components.
- Set up automated testing pipelines (unit + integration).
- Establish release checklist (feature toggles, migration scripts for storage).

